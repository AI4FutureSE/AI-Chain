<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Contents</title>
    <!-- bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
    <!-- icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.2/font/bootstrap-icons.css">
    <!-- jquery -->
    <script src="../plugin/jquery.min.js"></script>
    <!-- self-defined -->
    <link href="content.css" rel="stylesheet">
    <script src="content.js"></script>
</head>
<body>
<!-- navbar -->
<nav class="navbar navbar-expand-lg navbar-light my-navbar">
  <a class="navbar-brand" href="#cover">AI Chain</a>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link" href="#aichain">Chain</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#promptmanship">Promptmanship</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#sapper">Sapper</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#about">About Us</a>
      </li>
    </ul>
  </div>
</nav>

<main>
    <div id="main-content">
        <h1 class="main-title">AI Chain System Design</h1>
        <h2 class="main-subtitle"></h2>

        <img class="main-figure" src="../image/figures/Magic.jpg">
        <p class="figure-caption">Promptmanship: process, concepts, activities, and patterns</p>

        <p>
            The AI chain system design starts from the exploration phase and fully unfolds in the design phase. 
            The AI chain design and construction phases are highly iterative, and the AI chain system design will be iteratively optimized based on the actual running results of the AI chain. 
        </p>
        
        <p>           
            This activity is a continuation and a starting point: 
            continuation in the sense that it clarifies and refines the initial (vague) ``what we want'' and the approximate task model into specific AI chain requirements through requirement analysis, and a starting point in the sense that it produces the AI chain skeleton as the foundation for implementing the AI chain through task decomposition, separation of AI and non-AI concerns, and workflow walk-through. 
            These three activities adopt the basic principles of computational thinking and the modular design of software engineering, and will determine worker composition together with work-AI interaction modes, worker types (Software 3.0/2.0/1.0), and worker cooperation, forming a skeleton of AI chain.
        </p>
        
        <h2 class="main-subtitle">Requirement Analysis</h2>
        <p>
            The initial AI chain requirements provided by AI chain engineers are often incomplete or ambiguous. 
            Building the AI chain on such requirements makes it difficult to ``build the right AI chain''. 
            In software projects, it is usually necessary to clarify and refine requirements through communication between product managers and users. 
            We achieve this through an LLM-powered requirement co-pilot (implemented in the IDE's <a href="designviewpage">Design view</a>). 
            This co-pilot is a <a href="workerstereotypespage">Reverse Questioner</a> who engages in open-ended questioning with engineers around their initial requirements and task notes collected by the note-taking copilot in the <a href="explorationviewpage">Exploration view</a>. 
            Based on the engineer's answers, the requirement co-pilot iteratively rewrites and expands the AI chain requirements. 
        </p>
        
        <p>
            <b>To be fixed: For example, ... need to provide an example of multi-round requirement clarification. can be a demo video + some text explanation ... </b>
        </p>
        
        <h2 class="main-subtitle">Task Decomposition</h2>
        <p>
            When given a complex multiplication, such as 67*56, many people may not be able to provide the answer immediately. 
            However, this does not mean that humans lack the ability to perform two-digit multiplication. 
            With a pen and paper, it is not too difficult to stepwise calculate 60*50+7*50+60*6+7*6 and arrive at the final answer. 
        </p>
        <p>
            The same principle applies when working with foundation models. 
            When a model cannot solve a problem successfully in a single generative pass, we could consider how humans would divide and conquer such complex problems. 
            LLMs demonstrate strong task planning abilities (<a href="https://arxiv.org/abs/2204.01691">Ahn et al. 2022</a>, <a href="https://arxiv.org/abs/2209.11302">Singh et al. 2022</a>, <a href="https://arxiv.org/abs/2201.07207">Huang et al. 2022</a>).
            During the exploration phase, consulting the LLM can often obtain inspiration for task decomposition.
            Our IDE's Design view is equipped with a <a href="workerstereotypespage">Planner</a> co-pilot to generate a sequence of major steps for accomplishing the task requirement, which can be regarded as initial task decomposition.
            <b>To be fixed: For example, for the task requirement ``...'' of <a href="">xXiaoy</a>, it generates ?? steps: ..., ..., ... ??a case study example from xXiaoy</b>
        </p>

        <p>
            We can iteratively break down the problem into small, simpler ones.
            If a sub-task is still too complex, it can be further decomposed into simpler sub-tasks until each small problem can be handled by the model in a single generative pass. 
            This results in a hierarchy of sub-tasks, each of which is accomplished by an AI chain worker (<a href="aichainexamples.html">PCR-Chain</a>, <b>To be fixed: <a href="xXiaoy">xXiaoY task hierarhcy</a></b>). 
            If fine-grained tasks and coarse-grained tasks are the same, but only deal with increasingly simpler inputs, for example, substrings of a longstring, nested code blocks, then we can recursively call the same worker to simplify the input until the model can handle it, similar to least-to-most prompting (<a href="https://arxiv.org/abs/2205.10625">Zhou et al. 2022</a>).
        </p>
        <p>
            For intermediate sub-tasks, we need composite workers corresponding to the L4 work-AI interaction mode. 
            For leaf sub-task workers, we need to empirically determine the appropriate L1 to L3 interaction modes with increasing reasoning capability.
            <b>To be fixed:For example, ??worker-name1 in <a href="">xXiaoy</a> is a L1 worker, while ??worker-name2 is a L2 worker ... ??should assign L1-3 to worker 3.0 in the case study??? ...</b>
            Task decomposition requires mechanical sympathy to align task characteristics with model capabilities.
            That is, the appropriate granularity for task decomposition depends on the scale and capabilities of the foundation model. 
            For smaller models with weaker capabilities, tasks may need to be decomposed into finer granularity. 
            As model size and capabilities increase, they are more likely to be competent in coarser-grained tasks.
        </p>
        <p>
            An important question is whether we no longer need composite workers (i.e., task decomposition and AI chain), but only need a single worker with sufficient reasoning capabilities, as model capabilities scale up. 
            We believe we will see a left-shift in worker-AI interaction modes. 
            For a task that previously required a higher-level interaction mode, it can now be completed with a lower-level interaction mode as model capabilities improve. 
            Or, tasks that previously required a very complex AI chain can now be completed with a simple AI chain.
            However, AI chain engineering will not disappear as model capabilities increase, as task complexities that models could handle will increase at the same time.
            That is, many tasks that previous models could not handle can be completed with AI chains and stronger models. 
        </p>
      
        <h2 class="main-subtitle">Separation of AI and non-AI Concerns</h2>
        <p>
            An AI chain contains many workers, and not all workers need to be implemented based on the foundation model from both functional and economic perspectives.
            The economic perspective is an important factor to consider because foundation models usually require high-end computing resources or significant API usage expenses.
            We need to distinguish which workers need to leverage AI and which ones can use traditional programs. 
            For AI-based workers, we further distinguish which ones need to use the foundation model and which ones can use traditional ML models. 
        </p>
        <p>
            Through separation of concerns, we can achieve single responsibility and modular design, meaning that each worker in the system has a clear and specific responsibility. 
            This allows engineers to analyze and design different aspects of the AI service without being overwhelmed by its complexity.
            As a result, we can determine the most effective worker type for completing individial sub-tasks, whether it is completed by a Software 3.0, Software 2.0, or Software 1.0 worker. 
            Due to the workers' modular design and single responsibility, a worker's software paradigm can be easily swapped without affecting other parts of the system. 
            For example, we can replace a foundation model-based classifier with a performance-enhanced classifier fine-tuned on task data, or vice versa, replace a task-specific classifier trained on specific data with a foundation model-based classifier with better generalizability.
        </p>
        <p>
            For Software 3.0 workers, the core task is to determine <a href="workerstereotypepage">worker stereotype</a> and <a href="promptdesignpatternspage">design prompt</a>.
            Single responsibility worker makes it easier to determine a worker's distinct role and simplify its prompt design.
            Our IDE is equipped with a prompting co-pilot to create or revise prompts when generating AI chain steps from the task requirement or debugging prompts.
            <b>To be fixed: For example, for the step ``...'' of xXiaoy (Section~\ref{sec:xxiaoy}), this co-pilot generates a prompt ``...''.</b>
            Software 3.0 workers can be enhanced by external knowledge bases, tools or APIs (<a href="https://arxiv.org/abs/2101.06804">Liu et al. 2021</a>, <a href="https://arxiv.org/abs/2112.04426">Borgeaud et al. 2022</a>, <a href="https://arxiv.org/abs/2205.12255">TALM</a>, <a href="https://arxiv.org/abs/2211.10435">PAL</a>, <a href="http://arxiv.org/abs/2211.12588">Program of Thoughts</a>, <a href="https://arxiv.org/abs/2302.04761">Toolformer</a>, <a href="https://arxiv.org/abs/2303.16434">Taskmatrix.AI</a>, <a href="https://arxiv.org/abs/2303.17580">HuggingGPT</a>, <a href="https://openai.com/blog/chatgpt-plugins">ChatGPT Plugins</a>).
            For Software 2.0 or Software 1.0 workers, we need to determine the external knowledge base, task-specific models, or external tools to be used. 
        </p>

        <h2 class="main-subtitle">Workflow Walk-through</h2>
        <p>
            AI chain workers collaborate to complete tasks according to a workflow (see <a href="">AI chain examples</a> and our <a href="">AI chain showcases</a>). 
            This requires algorithmic thinking to develop a step-by-step process for solving problems.
            We recommend using <a href="http://www.workflowpatterns.com/">workflow patterns</a> to model AI chain workflows. 
            Note that a L3 worker expresses the workflow in its prompt internally, which is not for worker cooperation.
        </p>
        <p>
            The workflow needs to support control structures, such as conditional, loop, fork-join.
            For example, in order to avoid introducing errors into correct code, <a href="aichainexamples.html">PCR-Chain</a> only attempts to fix the code when the LLM determines that there are last-mile errors (judging whether the code has errors is easier than fixing the code). 
            <b>To be fixed: <a href="wenxiaojiecase">WenXiaoJie</a></b> works by iteratively expanding a story based on an outline, while maintaining coherence and consistency throughout the story.
            <b>To be fixed - use a fork-join example from our case?: When summarizing a long document, fork-join can be applied to summarize each section in parallel and then merge them into an overall summary of the document.</b>
        </p>
        <p>
            Meanwhile, each worker needs to define a function signature in terms of input and output as well as any pre/post-condition constraints, akin to interface specification in software engineering, so that workers can interact or communicate with one another.
            <b>To be fixed: For example, the worker-xxx in <a href="wenxiaojiecase">WenXiaoJie</a> takes ??three inputs (theme, audience, subject matter) and outputs a generic article outline.</b>
        </p>
    </div>
</main>

<!--<footer id="footer">-->
<!--</footer>-->

</body>
</html>